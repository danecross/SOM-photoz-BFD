{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "533d1d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tqdm\n",
    "from astropy.table import Table\n",
    "from random import sample, shuffle\n",
    "\n",
    "from NoiseSOM import *\n",
    "from pipeline_tools import *\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "import multiprocess as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66f5ffe",
   "metadata": {},
   "source": [
    "# Simulating Wide-Field Galaxies\n",
    "\n",
    "In order to create a mapping between the deep-field redshift map and the wide-field SOM, we need to know where the deep-field galaxies would be (statistically speaking) on the wide-field map. This means we need to take (~ noiseless) deep-field fluxes and make noisy realizations and map those onto the wide-field cells. Once we have these noise realizations, we will have everything we need to make a wide-cell-to-redshift map.\n",
    "\n",
    "BFD fluxes have (in theory) gaussian error. So, we will generate gaussian noise on deep-field fluxes with a distribution width drawn from average covariances in parts of the DES footprint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de00269",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dafd193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/pscratch/sd/d/dncross/SOM-photoz-BFD/data/covariances/BFD_covariances_masked.pkl', 'rb') as f:\n",
    "    covariances = pickle.load(f)\n",
    "    \n",
    "cat = Table.read('../data/deep_field_data/BFD/VALIDATION_cat_5E+04.fits')\n",
    "wideres = 32\n",
    "deepres = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5504d32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trained SOMs\n",
    "out_path = '../outputs/%s'\n",
    "\n",
    "SOMs_filenames = {\n",
    "    \"DES deep\": \"%s/SOM.pkl\"%(out_path%'BFD_deep/'), \n",
    "    \"DES wide\": \"%s/SOM.pkl\"%(out_path%'BFD/'), \n",
    "}\n",
    "\n",
    "SOMs = {key: load_SOM(SOMs_filenames[key]) for key in SOMs_filenames}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e7903e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['assigned DES deep']\n"
     ]
    }
   ],
   "source": [
    "# load deep assignments\n",
    "\n",
    "filename = \"../outputs/BFD_deep/assignments.pkl\"\n",
    "with open(filename, 'rb') as f:\n",
    "    fdata = pickle.load(f) ; assignments = []\n",
    "    for a in fdata:\n",
    "        assignments = np.append(assignments, a)\n",
    "    cat[\"assigned DES deep\"] = assignments\n",
    "    \n",
    "print([key for key in cat.colnames if \"assign\" in key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65ed008",
   "metadata": {},
   "source": [
    "# Deep to Wide Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "585ac07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_mask = np.array(covariances.nonzero()[1])\n",
    "noise_options = covariances.A[:,nonzero_mask]\n",
    "noise_options_idcs = np.where(nonzero_mask)\n",
    "n_realizations = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16741c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_wide(i):\n",
    "    \n",
    "    template_fluxes = cat['BFD_fluxes_ugrizY'][i][1:-1]\n",
    "    \n",
    "    idcs = np.array(sample(range(noise_options.shape[1]), n_realizations)) \n",
    "    wide_fluxes_err = np.array([np.sqrt(noise_options[i, idcs]) for i in range(noise_options.shape[0])]).T\n",
    "    wide_fluxes = np.array([[np.random.normal(f, ferr[j]) for j,f in enumerate(template_fluxes)]\n",
    "                            for ferr in wide_fluxes_err])\n",
    "        \n",
    "    min_SN = 7 ; max_SN=200\n",
    "    SN_ = SN(wide_fluxes,wide_fluxes_err)\n",
    "    mask = (SN_>min_SN) & (SN_<max_SN)\n",
    "    \n",
    "    wide_fluxes = wide_fluxes[mask]\n",
    "    wide_fluxes_err = wide_fluxes_err[mask]\n",
    "    \n",
    "    cells, _ = SOMs['DES wide'].classify(wide_fluxes, wide_fluxes_err)\n",
    "        \n",
    "    result = {}\n",
    "    result['deep position'] = cat['assigned DES deep'][i]\n",
    "    result['wide positions'] = cells\n",
    "    result['z'] = cat['COSMOS_PHOTZ'][i]\n",
    "    \n",
    "    result['wide fluxes'] = wide_fluxes\n",
    "    result['wide errors'] = wide_fluxes_err\n",
    "    result['healpix pos'] = noise_options[:,idcs] \n",
    "    \n",
    "    result['id'] = cat['id_array'][i]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9fc861",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 384/50000 [00:19<42:15, 19.57it/s] /global/homes/d/dncross/SOMs/SOM-photoz-BFD/src/pipeline_tools.py:18: RuntimeWarning: invalid value encountered in divide\n",
      "  return signal/noise\n",
      "  1%|          | 549/50000 [00:28<40:24, 20.40it/s]/global/homes/d/dncross/SOMs/SOM-photoz-BFD/src/pipeline_tools.py:18: RuntimeWarning: invalid value encountered in divide\n",
      "  return signal/noise\n",
      "  1%|          | 590/50000 [00:30<43:27, 18.95it/s]/global/homes/d/dncross/SOMs/SOM-photoz-BFD/src/pipeline_tools.py:18: RuntimeWarning: invalid value encountered in divide\n",
      "  return signal/noise\n",
      "  1%|▏         | 691/50000 [00:35<40:39, 20.21it/s]/global/homes/d/dncross/SOMs/SOM-photoz-BFD/src/pipeline_tools.py:18: RuntimeWarning: invalid value encountered in divide\n",
      "  return signal/noise\n",
      "  2%|▏         | 793/50000 [00:41<44:43, 18.34it/s]/global/homes/d/dncross/SOMs/SOM-photoz-BFD/src/pipeline_tools.py:18: RuntimeWarning: invalid value encountered in divide\n",
      "  return signal/noise\n",
      "  2%|▏         | 1124/50000 [00:57<40:27, 20.13it/s]/global/homes/d/dncross/SOMs/SOM-photoz-BFD/src/pipeline_tools.py:18: RuntimeWarning: invalid value encountered in divide\n",
      "  return signal/noise\n",
      "  3%|▎         | 1261/50000 [01:04<41:17, 19.67it/s]/global/homes/d/dncross/SOMs/SOM-photoz-BFD/src/pipeline_tools.py:18: RuntimeWarning: invalid value encountered in divide\n",
      "  return signal/noise\n",
      "  3%|▎         | 1316/50000 [01:07<46:10, 17.57it/s]/global/homes/d/dncross/SOMs/SOM-photoz-BFD/src/pipeline_tools.py:18: RuntimeWarning: invalid value encountered in divide\n",
      "  return signal/noise\n",
      "  3%|▎         | 1468/50000 [01:14<33:13, 24.35it/s]  /global/homes/d/dncross/SOMs/SOM-photoz-BFD/src/pipeline_tools.py:18: RuntimeWarning: invalid value encountered in divide\n",
      "  return signal/noise\n",
      "  4%|▍         | 2239/50000 [01:53<39:56, 19.93it/s]/global/homes/d/dncross/SOMs/SOM-photoz-BFD/src/pipeline_tools.py:18: RuntimeWarning: invalid value encountered in divide\n",
      "  return signal/noise\n",
      " 11%|█         | 5450/50000 [04:36<34:17, 21.65it/s]"
     ]
    }
   ],
   "source": [
    "fname = '../outputs/mock_assignments/simulations.pkl'\n",
    "if True: #not os.path.exists(fname):\n",
    "    args = [(i,) for i in range(len(cat['id_array']))]\n",
    "    p = mp.Pool(10) \n",
    "    \n",
    "    num_inds = len(cat['id_array'])\n",
    "    results = list(tqdm.tqdm(p.imap(map_to_wide, range(num_inds)), total=num_inds))\n",
    "    \n",
    "    d = {key: [] for key in results[0]}\n",
    "    for r in results:\n",
    "        for key in d:\n",
    "            d[key] += [r[key]]\n",
    "    \n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(d, f)\n",
    "else:\n",
    "    with open(fname, 'rb') as f:\n",
    "        d = pickle.load(f)\n",
    "\n",
    "\n",
    "deep_positions = d['deep position']\n",
    "wide_positions = d['wide positions']\n",
    "wide_fluxes = d['wide fluxes']\n",
    "wide_errs = d['wide errors']\n",
    "redshifts = d['z']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faca4f4f",
   "metadata": {},
   "source": [
    "# Data Checking\n",
    "\n",
    "- Make a mock catalog (first noise realization for each deep field galaxy)\n",
    "- Make sure the generated data looks similar to the actual BFD measurements\n",
    "- Make sure the colors/SN distributions make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1d051a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_cat = {\n",
    "    'positions': np.array([p for p in wide_positions], dtype=object),\n",
    "    'fluxes': np.array([f[5] for f in wide_fluxes if len(f)>5]),\n",
    "    'fluxes_err': np.array([fe[5] for fe in wide_errs if len(fe)>5])\n",
    "}\n",
    "\n",
    "data_path = '../data/wide_field_data/VALIDATION_CAT_1E+05.fits'\n",
    "d = Table.read(data_path, format='fits')\n",
    "    \n",
    "\n",
    "data_path = '../data/deep_field_data/BFD/VALIDATION_cat_5E+04.fits'\n",
    "d_deep = Table.read(data_path, format='fits')\n",
    "    \n",
    "print(d_deep.colnames)\n",
    "d['BFD_deep'] = [(f[1],f[2],f[3],f[4]) for f in d_deep['BFD_fluxes_ugrizY']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e599a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flux_to_mag(f, const=30):\n",
    "    return -2.5 * np.log10(f) + const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7f6786",
   "metadata": {},
   "outputs": [],
   "source": [
    "const = 30\n",
    "\n",
    "mag_mock = flux_to_mag(mock_cat['fluxes'], const)\n",
    "mag_bfd_wide = flux_to_mag(d['Mf_per_band'], const)\n",
    "mag_bfd_deep = flux_to_mag(d['BFD_deep'], const)\n",
    "\n",
    "mags = {key: [np.array([m[i] for m in mag_mock]), \n",
    "              np.array([m[i] for m in mag_bfd_wide]),\n",
    "              np.array([m[i] for m in mag_bfd_deep])]\n",
    "         for i,key in enumerate(['g', 'r', 'i', 'z'])}\n",
    "\n",
    "fig, axs = plt.subplots(1,3,figsize=(30, 10))\n",
    "\n",
    "ranges = [(10, 29), (15, 30), (15,30)]\n",
    "for i, ax in enumerate(axs):\n",
    "    for band in mags:\n",
    "        ax.hist(mags[band][i], 300, range=ranges[i], histtype='step', label=band, density=True)\n",
    "\n",
    "plt.legend()\n",
    "plt.suptitle(\"Magnitude Histogram\")\n",
    "axs[0].set_title(\"Mock Catalog\") ; axs[1].set_title(\"BFD wide\"); axs[2].set_title(\"BFD deep\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35c67d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(20,7))\n",
    "\n",
    "r = (-2.5, 2.5)\n",
    "for i, b1, b2 in zip(range(5), ['g', 'r', 'i', 'z'], ['r', 'i', 'z']):\n",
    "    mock_diff = mags[b1][0] - mags[b2][0] \n",
    "    axs[i].hist(mock_diff, 100, range=r, histtype='step', label=\"Wide Mock\", density=True)\n",
    "    \n",
    "    bfd_wide_diff = mags[b1][1] - mags[b2][1]\n",
    "    axs[i].hist(bfd_wide_diff, 100, range=r, histtype='step', label=\"BFD wide\", density=True)\n",
    "    \n",
    "    bfd_deep_diff = mags[b1][2] - mags[b2][2]\n",
    "    axs[i].hist(bfd_deep_diff, 100, range=r, histtype='step', label=\"BFD deep\", density=True)\n",
    "\n",
    "    print(len(bfd_wide_diff), len(bfd_wide_diff[~np.isnan(bfd_wide_diff)]))\n",
    "    print(len(bfd_deep_diff), len(bfd_wide_diff[~np.isnan(bfd_deep_diff)]))\n",
    "    \n",
    "    axs[i].set_title('%s-%s'%(b1,b2), fontsize=20)\n",
    "    print('%s-%s'%(b1,b2))\n",
    "    print(r'Wide Mock: %.02f $\\pm$ %.02f'%(np.nanmean(mock_diff), np.nanstd(mock_diff),))\n",
    "    print(r'BFD Wide: %.02f $\\pm$ %.02f'%(np.nanmedian(bfd_wide_diff), np.nanstd(bfd_wide_diff)))\n",
    "    print(r'BFD Deep: %.02f $\\pm$ %.02f'%(np.nanmedian(bfd_deep_diff), np.nanstd(bfd_deep_diff)))\n",
    "\n",
    "axs[-1].legend(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73e8597",
   "metadata": {},
   "outputs": [],
   "source": [
    "SN_mock = mock_cat['fluxes']/mock_cat['fluxes_err']\n",
    "SN_desd = d['Mf_per_band']/np.sqrt(d['cov_Mf_per_band'])\n",
    "\n",
    "fig, axs = plt.subplots(1,4,figsize=(30,10))\n",
    "titles = ['g band', 'r band', 'i band', 'z band']\n",
    "r=(-10,1000)\n",
    "for i, ax in enumerate(axs):\n",
    "    mock_f = [sn[i] for sn in SN_mock]\n",
    "    ax.hist(mock_f, 300, range=r, histtype='step', label='DES mock', density=True)\n",
    "    \n",
    "    desd_f = [sn[i] for sn in SN_desd]\n",
    "    h = ax.hist(desd_f, 300, range=r, histtype='step', label='DES wide', density=True)\n",
    "    ax.set_title(titles[i], fontsize=25)\n",
    "    \n",
    "    axs[i].text(0.5+i/12, 0.556,  \n",
    "                r'Mock: %.02f $\\pm$ %.02f'%(np.nanmedian(mock_f), np.nanstd(mock_f)),\n",
    "                horizontalalignment='center', verticalalignment='center', transform=ax.transAxes,\n",
    "                color=plt.cm.Set1(0), fontsize=25)\n",
    "    \n",
    "    axs[i].text(0.5+i/12, 0.5,  \n",
    "                r'Wide: %.02f $\\pm$ %.02f'%(np.nanmedian(desd_f), np.nanstd(desd_f)),\n",
    "                horizontalalignment='center', verticalalignment='center', transform=ax.transAxes,\n",
    "                color=plt.cm.Set1(1), fontsize=25)\n",
    "    \n",
    "plt.suptitle(\"S/N histograms\", fontsize=25)\n",
    "plt.legend(fontsize=25)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7e7f76",
   "metadata": {},
   "source": [
    "## Deep to Wide Maps\n",
    "\n",
    "Looks good, now we're going to show some samples of how adding noise to the wide galaxies changes the mapping from the deep SOM to the wide SOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2216f892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_SN(fluxes, fluxes_err):\n",
    "    SNs = []\n",
    "    for f, fe in zip(fluxes, fluxes_err):\n",
    "        g,r,i,z = f\n",
    "        ge, re, ie, ze = fe\n",
    "        signal = (0.7 * r**2 + 0.2 * i**2 + 0.1 * z**2)\n",
    "        noise = (0.7 * re**2 + 0.2 * ie**2 + 0.1 * ze**2)\n",
    "        SNs += [np.sqrt(signal/noise)]\n",
    "    return np.nanmean(SNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5d5338",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,4, figsize=(40,30))\n",
    "_max = -np.inf ; _min = np.inf\n",
    "\n",
    "nonempty_wp = [wps for wps in wide_positions if len(wps)>0]\n",
    "nonempty_f = [f for f,wps in zip(wide_fluxes,wide_positions) if len(wps)>0]\n",
    "nonempty_fe = [fe for fe,wps in zip(wide_errs,wide_positions) if len(wps)>0]\n",
    "for i,poss in enumerate(nonempty_wp):\n",
    "    if i >= 12: break\n",
    "    _max = max(_max, np.max(poss[0]))\n",
    "    _min = min(_min, np.min(poss[0]))\n",
    "    wide_occupation = np.histogram(poss,bins=wideres*wideres, range=(0,wideres*wideres))[0].reshape((wideres,wideres))\n",
    "    im = axs[i//4,i%4].imshow(1+wide_occupation, norm=LogNorm(vmin=1, vmax=50,))\n",
    "    \n",
    "    #divider = make_axes_locatable(axs[i%3,i//4])\n",
    "    #cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "    #fig.colorbar(im, cax=cax, orientation='vertical')\n",
    "    \n",
    "    SN = avg_SN(nonempty_f[i], nonempty_fe[i])\n",
    "    axs[i//4,i%4].set_title(\"avg S/N: %.02f\"%SN, fontsize=50)\n",
    "    axs[i//4,i%4].axis('off')\n",
    "    \n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb925108-617e-47d0-a49c-cb4b21a31114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fd2be0-dee6-4bf0-8189-c177a9b33578",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0292ff7f-14dd-45e2-81b4-ea05a3d22ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BFDenv",
   "language": "python",
   "name": "bfd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
